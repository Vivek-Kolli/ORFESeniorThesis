{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Telrq8h-2erV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6yNJo5u6GTi"
      },
      "outputs": [],
      "source": [
        "import anthropic, re\n",
        "from google.colab import userdata\n",
        "\n",
        "# API Key here!\n",
        "ANTHROPIC_API_KEY = \""\n",
        "# Using Claude Opus, Anthropic's most powerful model. State-of-the-art LLM as of 03/31/24.\n",
        "MODEL_NAME = \"claude-3-opus-20240229\"\n",
        "# \"claude-3-haiku-20240307\", \"claude-3-sonnet-20240229\", and \"claude-3-opus-20240229\"\n",
        "# where Haiku is the cheapest and Opus is the most powerful/expensive\n",
        "\n",
        "# Running this for one player with Haiku (approximately) takes 35 seconds and costs $0.005\n",
        "# Running this for one player with Opus (approximately) takes 205 seconds and costs $0.30\n",
        "\n",
        "CLIENT = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmSyYK6x_ME8"
      },
      "source": [
        "## Files we're working with\n",
        "\n",
        "### `examples.csv`\n",
        "\n",
        "- **Row 1** (topmost row): The name of each category.\n",
        "- **Row 2**: Name of the player whose review is an example of a 0.0 for this category.\n",
        "- **Row 3**: Name of the player whose review is an example of a 0.5 for this category.\n",
        "- **Row 4**: Name of the player whose review is an example of a 1.0 for this category.\n",
        "\n",
        "### `reviews.csv`\n",
        "\n",
        "- **Column A** (leftmost column): Name of the player.\n",
        "- **Column B**: Review of the player."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQW0LoIOAUDk"
      },
      "source": [
        "## Making the files workable\n",
        "\n",
        "1. **Save `reviews.csv` as a dictionary called `reviews_dict`, where:**\n",
        "   - The keys are from Column A.\n",
        "   - The values are from Column B.\n",
        "\n",
        "2. **Create a dictionary called `examples_dict`, where:**\n",
        "   - The keys are the names of each category.\n",
        "   - The values are a list of length 3, with each index containing:\n",
        "     - **Index 0**: Review of the player whose name was given as an example of a 0.0 in this category.\n",
        "     - **Index 1**: Review of the player whose name was given as an example of a 0.5 in this category.\n",
        "     - **Index 2**: Review of the player whose name was given as an example of a 1.0 in this category.\n",
        "\n",
        "To do Step 2, we search the name in the keys of `reviews_dict` and get the corresponding value (review)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZs4yEHT60Q1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "\n",
        "# Loading total reviews.csv into a dictionary\n",
        "reviews_df = pd.read_csv('reviews.csv', header = None)\n",
        "reviews_dict = pd.Series(reviews_df.iloc[:, 1].values,index=reviews_df.iloc[:, 0]).to_dict()\n",
        "print(len(reviews_dict))\n",
        "\n",
        "# Loading desired testing reviews.csv into a dictionary\n",
        "reviews1718cont_df = pd.read_csv('reviews1920updated.csv', header = None)\n",
        "reviews1718cont_dict = pd.Series(reviews1718cont_df.iloc[:, 1].values,index=reviews1718cont_df.iloc[:, 0]).to_dict()\n",
        "print(len(reviews1718cont_dict))\n",
        "\n",
        "# Loading the categories_examples.csv\n",
        "categories_examples_df = pd.read_csv('examples.csv')\n",
        "categories = categories_examples_df.columns.tolist()\n",
        "\n",
        "# Creating the desired dictionary\n",
        "examples_dict = {}\n",
        "for category in categories:\n",
        "    # Extracting the player names for 0.0, 0.5, and 1.0 examples\n",
        "    player_names = categories_examples_df[category].tolist()\n",
        "    # Getting the corresponding reviews from the reviews dictionary\n",
        "    reviews_list = [reviews_dict.get(name, \"Review not found\") for name in player_names]\n",
        "    examples_dict[category] = reviews_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCRCyGHPERWt"
      },
      "outputs": [],
      "source": [
        "# Check that reviews looks right\n",
        "reviews_dict[\"Lonzo Ball\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-ZvR6IzEbIO"
      },
      "outputs": [],
      "source": [
        "# Check that examples looks right\n",
        "examples_dict[\"Athleticism\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0nFesn-K7rd"
      },
      "outputs": [],
      "source": [
        "# Check that reviews looks right\n",
        "reviews1718cont_dict[\"Jason Preston\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcZpbJFhOmr_"
      },
      "source": [
        "## Feeding Data into the LLM\n",
        "\n",
        "Now, we use the data from `reviews_dict` and `examples_dict` to generate prompts for the language model (LLM) as follows:\n",
        "\n",
        "1. **Iterate through every key (player name) in `reviews_dict`. For each key:**\n",
        "   - `{TEXT}` = The key's value (the player's review).\n",
        "\n",
        "2. **Then, for each player, iterate through every key (category) in `examples_dict` and its corresponding values (examples):**\n",
        "   - `{CATEGORY}` = Key from `examples_dict`.\n",
        "   - `{00_EXAMPLE}` = 0th index value from the list of examples in `examples_dict`.\n",
        "   - `{05_EXAMPLE}` = 1st index value from the list of examples in `examples_dict`.\n",
        "   - `{10_EXAMPLE}` = 2nd index value from the list of examples in `examples_dict`.\n",
        "\n",
        "This process involves evaluating each player across every category by running the LLM for each scenario.\n",
        "\n",
        "### Writing to `results_dict`\n",
        "\n",
        "We store the outcomes in a dictionary named `results_dict`, structured as:\n",
        "- **Key**: Player name.\n",
        "- **Value**: List of dictionaries, where each item contains:\n",
        "  - **Key**: Category name.\n",
        "  - **Value**: List of length 3, with each index containing:\n",
        "    - **Index 0**: Raw output from the LLM.\n",
        "    - **Index 1**: Text within the `<reasoning>` tags of the LLM output, or null if tags weren't found.\n",
        "    - **Index 2**: Text within the `<rating>` tags of the LLM output, or null if tags weren't found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JTuXu0VE8H7"
      },
      "outputs": [],
      "source": [
        "prompt = '''\n",
        "Here is the text of a qualitative review of a basketball player:\n",
        "\n",
        "<review>\n",
        "{TEXT}\n",
        "</review>\n",
        "\n",
        "Your task is to analyze the review text above and output a quantitative rating for the player in the\n",
        "following category: {CATEGORY}\n",
        "\n",
        "The rating should be a decimal between 0 and 1, based on this scale:\n",
        "0 = The review describes the player as terrible in this category\n",
        "0.5 = The review describes the player as neutral in this category\n",
        "1 = The review describes the player as phenomenal in this category\n",
        "Output NA if the category is not captured in the review.\n",
        "\n",
        "To help calibrate your rating scale, here are some example reviews and their ratings in the\n",
        "{CATEGORY} category:\n",
        "\n",
        "<example_00>\n",
        "{EXAMPLE_00}\n",
        "</example_00>\n",
        "This review corresponds to a 0 rating in the {CATEGORY} category.\n",
        "\n",
        "<example_05>\n",
        "{EXAMPLE_05}\n",
        "</example_05>\n",
        "This review corresponds to a 0.5 rating in the {CATEGORY} category.\n",
        "\n",
        "<example_10>\n",
        "{EXAMPLE_10}\n",
        "</example_10>\n",
        "This review corresponds to a 1 rating in the {CATEGORY} category.\n",
        "\n",
        "Carefully read the review text provided, and compare it to the example reviews to determine the most\n",
        "appropriate rating in the {CATEGORY} category for this player.\n",
        "\n",
        "First, write your reasoning for the rating you will give inside <reasoning> tags. Explain how the\n",
        "review compares to the 0, 0.5 and 1 example reviews in terms of what it says about the player's\n",
        "abilities in the {CATEGORY} category.\n",
        "\n",
        "Then, output your final quantitative rating inside <rating> tags. This should be a decimal between 0\n",
        "and 1, or NA if the category is not captured in the review. Make sure your rating is well-calibrated\n",
        "to the 0, 0.5 and 1 example reviews provided.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0NE9K0IQN5H"
      },
      "outputs": [],
      "source": [
        "def extract_between_tags(tag: str, string: str, strip: bool = False) -> list[str]:\n",
        "    ext_list = re.findall(f\"<{tag}>(.+?)</{tag}>\", string, re.DOTALL)\n",
        "    if strip:\n",
        "        ext_list = [e.strip() for e in ext_list]\n",
        "    return ext_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew7-7VhfQB8Z"
      },
      "outputs": [],
      "source": [
        "# Initialize results storage\n",
        "results_dict = {}\n",
        "\n",
        "# For tracking progress on run\n",
        "counter = 0\n",
        "\n",
        "# Change to whatever smaller dictionary you created\n",
        "for player, review in reviews1718cont_dict.items():\n",
        "    print(str(counter) + \" \" + player)\n",
        "    print()\n",
        "    results_dict[player] = []\n",
        "    for category, examples in examples_dict.items():\n",
        "        # Replace variables in prompt\n",
        "        prompt_with_variables = prompt.format(\n",
        "            TEXT=review,\n",
        "            CATEGORY=category,\n",
        "            EXAMPLE_00=examples[0],\n",
        "            EXAMPLE_05=examples[1],\n",
        "            EXAMPLE_10=examples[2]\n",
        "        )\n",
        "        # Execute the LLM call\n",
        "        llm_output = CLIENT.messages.create(\n",
        "            model=MODEL_NAME,\n",
        "            max_tokens=4096,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\":  prompt_with_variables\n",
        "                },\n",
        "            ],\n",
        "        ).content[0].text\n",
        "        # Extract reasoning and rating\n",
        "        reasoning = extract_between_tags(\"reasoning\", llm_output, strip=True)\n",
        "        rating = extract_between_tags(\"rating\", llm_output, strip=True)\n",
        "        # Store results\n",
        "        results_dict[player].append({\n",
        "            category: [\n",
        "                llm_output,  # Raw LLM output\n",
        "                reasoning[0] if reasoning else None,  # Extracted reasoning\n",
        "                rating[0] if rating else None,  # Extracted rating\n",
        "            ]\n",
        "        })\n",
        "    counter+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfrFPqQrTJHG"
      },
      "outputs": [],
      "source": [
        "# For checking correct outcome for a player (Pick a player in the dictionary you just tested)\n",
        "chandler = results_dict['Chandler Hutchison']\n",
        "\n",
        "for category_dict in chandler:\n",
        "    for category, details in category_dict.items():\n",
        "        # Extract reasoning and rating, assuming the reasoning is the second item in the list and rating is the third\n",
        "        reasoning, rating = details[1], details[2]\n",
        "        print(f\"Category: {category}\\nRating: {rating}\\nReasoning: {reasoning}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KUIwl8AP0bg"
      },
      "source": [
        "### Saving to CSV\n",
        "\n",
        "Finally, we save this information to a CSV named \"results\", where:\n",
        "- **Column A** (leftmost column): Contains the names of the players.\n",
        "- **The remaining columns**: Contain the unpacked values from `results_dict`, with the column titles in the form:\n",
        "  - `[Category Name] - Raw`\n",
        "  - `[Category Name] - Reasoning`\n",
        "  - `[Category Name] - Rating`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSi48Q7UR-D-"
      },
      "outputs": [],
      "source": [
        "# Flatten the results_dict for DataFrame conversion\n",
        "rows = []\n",
        "for player, categories in results_dict.items():\n",
        "    row = {'Player': player}\n",
        "    for category_result in categories:\n",
        "        for category, values in category_result.items():\n",
        "            row[f\"{category} - Raw\"] = values[0]\n",
        "            row[f\"{category} - Reasoning\"] = values[1]\n",
        "            row[f\"{category} - Rating\"] = values[2]\n",
        "    rows.append(row)\n",
        "\n",
        "df = DataFrame(rows)\n",
        "\n",
        "# Download CSV of data\n",
        "df.to_csv(\"results2017.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
