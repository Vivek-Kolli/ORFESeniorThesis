{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPabuHhkmC7FJSvFG+wYbz0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install chart_studio\n"
      ],
      "metadata": {
        "id": "sYyut6NE4wzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_validate, KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Loading dataset\n",
        "df = pd.read_csv('/content/College to NBA.csv')\n",
        "\n",
        "# Define predictors and the target variable, excluding specific columns\n",
        "predictors = df.select_dtypes(include=['float64', 'int64']).drop(['Draft Year', 'Pk', 'WS/48', 'VORP', 'VORP/48', 'BPM', 'WS'], axis=1).columns\n",
        "X = df[predictors]\n",
        "y = df['VORP/48']\n",
        "\n",
        "# Initial Random Forest model to determine feature importances\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)  # Using all data to get feature importance\n",
        "\n",
        "# Get feature importances and sort them\n",
        "feature_importances = pd.Series(rf.feature_importances_, index=predictors).sort_values(ascending=False)\n",
        "top_n_features = feature_importances.head(15).index.tolist()\n",
        "X_selected = df[top_n_features]\n",
        "\n",
        "# Normalize the selected features\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X_selected)\n",
        "\n",
        "# K-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Define scorers for MSE and R^2\n",
        "scorers = {\n",
        "    'MSE': make_scorer(mean_squared_error, greater_is_better=False),\n",
        "    'r2': make_scorer(r2_score)\n",
        "}\n",
        "\n",
        "cv_results = cross_validate(RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "                            X_normalized, y, cv=kf, scoring=scorers, return_train_score=True)\n",
        "\n",
        "# Calculate average scores\n",
        "average_train_mse = -np.mean(cv_results['train_MSE'])\n",
        "average_test_mse = -np.mean(cv_results['test_MSE'])\n",
        "average_train_rmse = np.sqrt(average_train_mse)\n",
        "average_test_rmse = np.sqrt(average_test_mse)\n",
        "average_train_r2 = np.mean(cv_results['train_r2'])\n",
        "average_test_r2 = np.mean(cv_results['test_r2'])\n",
        "\n",
        "# Print results\n",
        "print(f\"Selected Features: {top_n_features}\")\n",
        "print(f\"Average Training MSE: {average_train_mse}\")\n",
        "print(f\"Average Training RMSE: {average_train_rmse}\")\n",
        "print(f\"Average Training R^2: {average_train_r2}\")\n",
        "print(f\"Average Testing MSE: {average_test_mse}\")\n",
        "print(f\"Average Testing RMSE: {average_test_rmse}\")\n",
        "print(f\"Average Testing R^2: {average_test_r2}\")"
      ],
      "metadata": {
        "id": "XN6zHeWvq0F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_validate, KFold\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "def run_model(dataset_path):\n",
        "    df = pd.read_csv(dataset_path)\n",
        "    predictors = df.select_dtypes(include=['float64', 'int64']).drop(['Draft Year', 'Pk', 'WS/48', 'VORP', 'VORP/48', 'BPM', 'WS'], axis=1).columns\n",
        "    X = df[predictors]\n",
        "    y = df['WS/48']\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scorers = {\n",
        "        'MSE': make_scorer(mean_squared_error, greater_is_better=False),\n",
        "        'r2': 'r2'\n",
        "    }\n",
        "\n",
        "    cv_results = cross_validate(RandomForestRegressor(random_state=42), X_imputed, y, cv=kf, scoring=scorers, return_train_score=True)\n",
        "\n",
        "    train_rmse = np.sqrt(-cv_results['train_MSE'].mean())\n",
        "    test_rmse = np.sqrt(-cv_results['test_MSE'].mean())\n",
        "\n",
        "    return {\n",
        "        'train_mse': -cv_results['train_MSE'].mean(),\n",
        "        'train_rmse': train_rmse,\n",
        "        'train_r2': cv_results['train_r2'].mean(),\n",
        "        'test_mse': -cv_results['test_MSE'].mean(),\n",
        "        'test_rmse': test_rmse,\n",
        "        'test_r2': cv_results['test_r2'].mean()\n",
        "    }\n",
        "\n",
        "# Paths to datasets\n",
        "dataset_paths = ['/content/College to NBA.csv', '/content/Quantitative Stats (College, NBA, Combine).csv', '/content/Full Dataset (Imputed Values).csv']\n",
        "metrics = [run_model(path) for path in dataset_paths]\n",
        "\n",
        "# Printing the metrics for each dataset\n",
        "for i, metric in enumerate(metrics, start=1):\n",
        "    print(f\"Metrics for Dataset {i}: {metric}\")\n"
      ],
      "metadata": {
        "id": "5e3BiZ9sprX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## FINAL MODEL\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, cross_validate, RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "def run_model(dataset_path):\n",
        "    # Loading dataset\n",
        "    df = pd.read_csv(dataset_path)\n",
        "\n",
        "    # Define predictors and the target variable, excluding specific columns\n",
        "    predictors = df.select_dtypes(include=['float64', 'int64']).drop(['Draft Year', 'Pk', 'WS/48', 'VORP', 'VORP/48', 'BPM', 'WS'], axis=1)\n",
        "    X = df[predictors.columns]\n",
        "    y = df['VORP/48']\n",
        "\n",
        "    # Impute missing values\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "    # Define a K-Fold cross-validator\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    param_dist = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "        'max_features': ['auto', 'sqrt']\n",
        "    }\n",
        "\n",
        "    rf = RandomForestRegressor(random_state=42)\n",
        "    random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=10, cv=kf, scoring='r2', random_state=42)\n",
        "    random_search.fit(X_imputed, y)\n",
        "\n",
        "    # Best model selection and cross-validation\n",
        "    best_model = random_search.best_estimator_\n",
        "    cv_results = cross_validate(best_model, X_imputed, y, cv=kf,\n",
        "                                scoring={'MSE': make_scorer(mean_squared_error, greater_is_better=False), 'r2': 'r2'},\n",
        "                                return_train_score=True)\n",
        "\n",
        "    # Calculate and print MSE and RMSE for training and testing\n",
        "    train_mse = -cv_results['train_MSE'].mean()\n",
        "    test_mse = -cv_results['test_MSE'].mean()\n",
        "    train_rmse = np.sqrt(train_mse)\n",
        "    test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "    print(f\"Train MSE: {train_mse}, Train RMSE: {train_rmse}\")\n",
        "    print(f\"Test MSE: {test_mse}, Test RMSE: {test_rmse}\")\n",
        "\n",
        "    return {\n",
        "        'best_params': random_search.best_params_,\n",
        "        'train_mse': train_mse,\n",
        "        'train_rmse': train_rmse,\n",
        "        'train_r2': cv_results['train_r2'].mean(),\n",
        "        'test_mse': test_mse,\n",
        "        'test_rmse': test_rmse,\n",
        "        'test_r2': cv_results['test_r2'].mean()\n",
        "    }\n",
        "\n",
        "# Paths to datasets\n",
        "dataset_paths = ['/content/College to NBA.csv', '/content/Quantitative Stats (College, NBA, Combine).csv', '/content/Full Dataset (Imputed Values).csv']\n",
        "metrics = [run_model(path) for path in dataset_paths]\n",
        "\n",
        "# Printing the metrics for each dataset\n",
        "for i, metric in enumerate(metrics, start=1):\n",
        "    print(f\"Metrics for Dataset {i}: {metric}\")\n"
      ],
      "metadata": {
        "id": "tDWej4mePcE8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}